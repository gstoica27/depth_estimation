import pandas, cv2
import tensorflow as tf
import numpy as np
import math
import matplotlib.pyplot as plt
# rdfdfdf
# Get data

IMAGE_HEIGHT = 188
IMAGE_WIDTH = 621

def variable_summaries(var):
  with tf.name_scope('summaries'):
    mean = tf.reduce_mean(var)
    tf.summary.scalar('mean', mean)
    with tf.name_scope('stddev'):
      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))
    tf.summary.scalar('stddev', stddev)
    tf.summary.scalar('max', tf.reduce_max(var))
    tf.summary.scalar('min', tf.reduce_min(var))
    tf.summary.histogram('histogram', var)

def read_references(size):
    data = []
    for reference_index in range(0, size):
        if reference_index < 10:
            data += ["0000{}".format(reference_index)]
        elif reference_index < 100:
            data += ["000{}".format(reference_index)]
        else:
            data += ["00{}".format(reference_index)]
    return np.array(data)

# Get train and test reference splits
def train_test_split(references, split = .8):
    size = len(references)
    np.random.shuffle(references)
    split_pivot = int(math.floor(size * split))
    train_references = references[:split_pivot]
    test_references = references[split_pivot:]
    return train_references, test_references

# Declare Convolutional block
def convBlock(scope_name, input_layer, kernel_shape, bias_shape, strides = [1,1,1,1], padding = "SAME", reuse = False):
    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:
        # if reuse:
        #     scope.reuse_variables() truncated_normal_initializer
        kernel = tf.get_variable("weights", kernel_shape, initializer = tf.truncated_normal_initializer())
        conv = tf.nn.conv2d(name = "convolution", input = input_layer, filter = kernel, strides = strides, padding = padding)
        bias = tf.get_variable("bias", bias_shape, initializer = tf.constant_initializer(.01))
        conv_plus_bias = tf.nn.bias_add(conv, bias, name = "bias_add")
        conv_activation = tf.nn.relu(conv_plus_bias, scope.name)
        return conv_activation

# use inverted MSE loss
def loss(prediction, ground_truth):
    global IMAGE_HEIGHT, IMAGE_WIDTH
    size = int(IMAGE_HEIGHT/2.0 * math.ceil(IMAGE_WIDTH/2.0))
    prediction_flat = tf.reshape(prediction, [-1,size], name = "prediction_flatten")

    # ground_truth_reshaped = tf.reshape(ground_truth, [-1, 375, 1242, 1], name = "gt_reshaped")
    ground_truth_downsampled = tf.nn.max_pool(name = "gt_downsampled", 
                           value = ground_truth, 
                           ksize = [1, 2, 2, 1], 
                           strides = [1, 2, 2, 1], 
                           padding = "SAME")
    # print("HEYYYY!!!")
    print(ground_truth_downsampled.get_shape().as_list())
    # ground_truth_downsampled = tf.Print(ground_truth_downsampled.get_shape(), [ground_truth_downsampled], "The shape is: ")
    # print("yo")
    ground_truth_flat = tf.reshape(ground_truth_downsampled, [-1, size], name = "gt_flattened")

    ground_truth_flat_inverted = tf.divide(1.0, tf.add(ground_truth_flat,  1), name = "gt_inverted")
    prediction_flat_inverted = tf.divide(1.0, tf.add(prediction_flat, 1), name = "prediction_inverted")

    # loss = tf.losses.mean_squared_error(labels = ground_truth_flat_inverted, predictions = prediction_flat_inverted)
    loss_abs = tf.losses.absolute_difference(labels = ground_truth_flat_inverted, predictions = prediction_flat_inverted)
    loss = tf.reduce_mean(loss_abs)
    
    return loss

# Burrowed from Masazl
def maselz_loss(logits, depths):
    global IMAGE_HEIGHT, IMAGE_WIDTH
    size = (IMAGE_HEIGHT/2.0)* math.ceil(IMAGE_WIDTH/2.0)
    predict = tf.reshape(logits, [-1,int(size)])
    depths_downsampled = tf.nn.max_pool(name = "gt_downsampled", 
                           value = depths, 
                           ksize = [1, 2, 2, 1], 
                           strides = [1, 2, 2, 1], 
                           padding = "SAME")

    target = tf.reshape(depths_downsampled, [-1, int(size)])

    d = tf.subtract(predict, target)
    square_d = tf.square(d)
    sum_square_d = tf.reduce_sum(square_d, 1)
    sum_d = tf.reduce_sum(d, 1)
    sqare_sum_d = tf.square(sum_d)
    loss = tf.reduce_mean(sum_square_d /size - 0.5*sqare_sum_d / math.pow(size, 2))
    return loss



# 3 Conv Model + Max pooling
def model(input_layer):
    conv1 = convBlock(scope_name = "conv1", 
                      input_layer = input_layer, 
                      kernel_shape = [3, 3, 3, 50], 
                      bias_shape = [50], 
                      strides = [1, 1, 1, 1], 
                      padding = "SAME", 
                      reuse = True)
    conv2 = convBlock(scope_name = "conv2", 
                      input_layer = conv1, 
                      kernel_shape = [3, 3, 50, 100], 
                      bias_shape = [100], 
                      strides = [1, 1, 1, 1], 
                      padding = "SAME", 
                      reuse = True)
    pool1 = tf.nn.max_pool(name = "pool1", 
                           value = conv2, 
                           ksize = [1, 2, 2, 1], 
                           strides = [1, 2, 2, 1], 
                           padding = "SAME")
    conv3 = convBlock(scope_name = "conv3", 
                      input_layer = pool1, 
                      kernel_shape = [3, 3, 100, 1], 
                      bias_shape = [1], 
                      strides = [1, 1, 1, 1], 
                      padding = "SAME", 
                      reuse = True)

    print(conv3.get_shape().as_list())
    return conv3



# reererre
def train(sess, train_references, BATCH_SIZE, num_iterations=10, run_keys = [], feed_dict_keys = []):
    global IMAGE_HEIGHT, IMAGE_WIDTH
    # Initialize Variables + extract paramaters
    train_opt, model_loss, prediction, gvs = run_keys
    input_layer, ground_truth = feed_dict_keys
    input_batch = np.zeros([])
    ground_truth_batch = np.zeros([])
    total_loss = 0

    # Initialize Plotting Variables
    epochs = [i for i in range(num_iterations)]
    epoch_loss = [0 for i in range(num_iterations)]

    for iteration in range(num_iterations):
        total_iteration_loss = 0
        index = 0
        while index < len(train_references):
            # reset batch counter
            current_batch = 0
            # make batch. 
            # Check that current batch is smaller than batch size + train reference index is in bounds. 
            while current_batch < BATCH_SIZE and index < len(train_references):
                train_reference = train_references[index]
                depth_filename = "/Users/georgestoica/Desktop/Research/Mini-Project/ds_depth/{}.png".format(train_reference)
                input_filename = "/Users/georgestoica/Desktop/Research/Mini-Project/ds_image/{}.png".format(train_reference)
                depth = np.reshape(cv2.imread(depth_filename, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH), (1, IMAGE_HEIGHT, IMAGE_WIDTH, 1))
                input_img = np.reshape(cv2.imread(input_filename, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH), (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3))
                # set batch arrays if dimensions are un-initialized
                if current_batch == 0:
                    input_batch = input_img
                    ground_truth_batch = depth
                # batch arrays well defined
                else:
                    input_batch = np.concatenate((input_batch, input_img), axis = 0)
                    ground_truth_batch = np.concatenate((ground_truth_batch, depth), axis = 0)
                # increment current batch counter + train reference index
                current_batch += 1
                index += 1
            # reshape batches for model compatibility
            input_batch = np.reshape(input_batch, (BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, 3))
            ground_truth_batch = np.reshape(ground_truth_batch, (BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, 1))

            # run model
            _dummy1, loss, _dummy3 = sess.run([train_opt, model_loss, prediction], 
                                                      feed_dict = {input_layer: input_batch, 
                                                                   ground_truth: ground_truth_batch})
            # for gv in gvs:
            #     print(str(sess.run(gv[0], feed_dict = {input_layer: input_batch, 
            #                                                        ground_truth: ground_truth_batch})) + " - " + gv[1].name)
            total_iteration_loss += loss
            # print("The loss for this batch is: " + str(loss))
            
        
        avg_iteration_loss = total_iteration_loss / float(len(train_references))
        print("The average loss for iteration {} is: ".format(iteration+1) + str(avg_iteration_loss))

        epoch_loss[iteration] = total_iteration_loss
        total_loss += total_iteration_loss
    avg_total_loss = total_loss / float(num_iterations * len(train_references))
    print("The total average loss over all iterations is: " + str(avg_total_loss))
    plt.plot(epochs, epoch_loss, 'b-')
    plt.show()


def test(sess, test_references, run_keys = [], feed_dict_keys = []):
    global IMAGE_HEIGHT, IMAGE_WIDTH
    model_loss, prediction = run_keys
    input_layer, ground_truth = feed_dict_keys
    total_loss = 0
    for test_reference in test_references:
        depth_filename = "/Users/georgestoica/Desktop/Research/Mini-Project/ds_depth/{}.png".format(test_reference)
        input_filename = "/Users/georgestoica/Desktop/Research/Mini-Project/ds_image/{}.png".format(test_reference)
        depth = np.reshape(cv2.imread(depth_filename, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH), (1, IMAGE_HEIGHT, IMAGE_WIDTH, 1))
        input_img = np.reshape(cv2.imread(input_filename, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH), (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3))

        loss, pred = sess.run([model_loss, prediction], 
                                                      feed_dict = {input_layer: input_img, 
                                                                   ground_truth: depth})
        # Encode Image
        pred_rs = tf.reshape(pred, [94, 311, 1])
        pred_u16 = tf.image.convert_image_dtype(pred_rs, tf.uint16)
        pred_enc = tf.image.encode_png(pred_u16)
        depth_fpath = tf.constant("/Users/georgestoica/Desktop/Research/Mini-Project/pred_depth/{}.png".format(test_reference))
        depth_write = tf.write_file(depth_fpath, pred_enc)
        dummy_ = sess.run(depth_write)


        total_loss += loss
    avg_loss = float(total_loss) / float(len(test_references))    
    print("The average test loss is: " + str(avg_loss))


def main(unusedargv):
    global IMAGE_HEIGHT, IMAGE_WIDTH
    BATCH_SIZE = 8
    references = read_references(size = 10)
    train_references, test_references = train_test_split(references, split = .8)
    with tf.Graph().as_default():
        # Set up Placeholders
        input_layer = tf.placeholder(tf.float32, shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, 3))
        ground_truth = tf.placeholder(tf.float32, shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, 1))
        # Set up Build Recipe
        prediction = model(input_layer)
        model_loss = maselz_loss(prediction, ground_truth)

        # Set up Learner
        optimizer = tf.train.AdagradOptimizer(1e-06)
        gvs = optimizer.compute_gradients(model_loss)
        train_opt = optimizer.apply_gradients(gvs)
        init_op = tf.global_variables_initializer()
        sess = tf.Session()
        sess.run(init_op)
        writer = tf.summary.FileWriter("/tmp/log/test", sess.graph)

        # train
        print("Training...")
        run_keys_train = [train_opt, model_loss, prediction, gvs]
        feed_dict_keys_train = [input_layer, ground_truth]
        train(sess, 
              train_references, 
              BATCH_SIZE, 
              num_iterations = 5,
              run_keys = run_keys_train, 
              feed_dict_keys = feed_dict_keys_train)
        print("Testing....")
        # test
        run_keys_test = [model_loss, prediction]
        feed_dict_keys_test = [input_layer, ground_truth]
        test(sess, 
            test_references, 
            run_keys = run_keys_test, 
            feed_dict_keys = feed_dict_keys_test)

        print("Done")
        sess.close()
        writer.close()



if __name__ == "__main__":
    tf.app.run()






    
